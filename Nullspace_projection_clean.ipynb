{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ada9b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "data = torch.load(\"d3s_training_activations.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c8fb23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = data['activations'].reshape(-1,2048)\n",
    "classes = data['classes'].reshape(-1)\n",
    "backgrounds = data['backgrounds'].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d069549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and validation sets\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "val_indices = np.random.choice(100000,size=10000,replace=False)\n",
    "val_indices.sort()\n",
    "train_indices = np.array(list(set(range(100000)) - set(list(val_indices))))\n",
    "train_indices.sort()\n",
    "train_activations = activations[train_indices]\n",
    "train_classes = classes[train_indices]\n",
    "train_backgrounds = backgrounds[train_indices]\n",
    "\n",
    "val_activations = activations[val_indices]\n",
    "val_classes = classes[val_indices]\n",
    "val_backgrounds = backgrounds[val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94a7b032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36887d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Section adapted from https://github.com/shauli-ravfogel/nullspace_projection ###\n",
    "\n",
    "import scipy\n",
    "from typing import List\n",
    "\n",
    "def get_rowspace_projection(W: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    :param W: the matrix over its nullspace to project\n",
    "    :return: the projection matrix over the rowspace\n",
    "    \"\"\"\n",
    "\n",
    "    if np.allclose(W, 0):\n",
    "        w_basis = np.zeros_like(W.T)\n",
    "    else:\n",
    "        w_basis = scipy.linalg.orth(W.T) # orthogonal basis\n",
    "\n",
    "    P_W = w_basis.dot(w_basis.T) # orthogonal projection on W's rowspace\n",
    "\n",
    "    return P_W\n",
    "\n",
    "def get_projection_to_intersection_of_nullspaces(rowspace_projection_matrices: List[np.ndarray], input_dim: int):\n",
    "    \"\"\"\n",
    "    Given a list of rowspace projection matrices P_R(w_1), ..., P_R(w_n),\n",
    "    this function calculates the projection to the intersection of all nullspasces of the matrices w_1, ..., w_n.\n",
    "    uses the intersection-projection formula of Ben-Israel 2013 http://benisrael.net/BEN-ISRAEL-NOV-30-13.pdf:\n",
    "    N(w1)∩ N(w2) ∩ ... ∩ N(wn) = N(P_R(w1) + P_R(w2) + ... + P_R(wn))\n",
    "    :param rowspace_projection_matrices: List[np.array], a list of rowspace projections\n",
    "    :param dim: input dim\n",
    "    \"\"\"\n",
    "\n",
    "    I = np.eye(input_dim)\n",
    "    Q = np.sum(rowspace_projection_matrices, axis = 0)\n",
    "    P = I - get_rowspace_projection(Q)\n",
    "\n",
    "    return P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "488b7aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faster implementation for orthogonal projection, using GPU\n",
    "## Section adapted from https://github.com/shauli-ravfogel/nullspace_projection ###\n",
    "\n",
    "import scipy\n",
    "from typing import List\n",
    "\n",
    "def orth_torch(A):\n",
    "    u, s, vh = torch.linalg.svd(torch.tensor(A).cuda(), full_matrices=False)\n",
    "    M, N = u.shape[0], vh.shape[1]\n",
    "    rcond = torch.finfo(s.dtype).eps * max(M, N)\n",
    "    tol = torch.amax(s.reshape(-1)) * rcond\n",
    "    num = torch.sum(s > tol, dtype=int)\n",
    "    Q = u[:, :num]\n",
    "    return Q.cpu().numpy()\n",
    "\n",
    "\n",
    "\n",
    "def get_rowspace_projection_torch(W: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    :param W: the matrix over its nullspace to project\n",
    "    :return: the projection matrix over the rowspace\n",
    "    \"\"\"\n",
    "\n",
    "    if np.allclose(W, 0):\n",
    "        w_basis = np.zeros_like(W.T)\n",
    "    else:\n",
    "        w_basis = orth_torch(W.T) # orthogonal basis\n",
    "\n",
    "    P_W = w_basis.dot(w_basis.T) # orthogonal projection on W's rowspace\n",
    "\n",
    "    return P_W\n",
    "\n",
    "def get_projection_to_intersection_of_nullspaces_torch(rowspace_projection_matrices: List[np.ndarray], input_dim: int):\n",
    "    \"\"\"\n",
    "    Given a list of rowspace projection matrices P_R(w_1), ..., P_R(w_n),\n",
    "    this function calculates the projection to the intersection of all nullspasces of the matrices w_1, ..., w_n.\n",
    "    uses the intersection-projection formula of Ben-Israel 2013 http://benisrael.net/BEN-ISRAEL-NOV-30-13.pdf:\n",
    "    N(w1)∩ N(w2) ∩ ... ∩ N(wn) = N(P_R(w1) + P_R(w2) + ... + P_R(wn))\n",
    "    :param rowspace_projection_matrices: List[np.array], a list of rowspace projections\n",
    "    :param dim: input dim\n",
    "    \"\"\"\n",
    "\n",
    "    I = np.eye(input_dim)\n",
    "    Q = np.sum(rowspace_projection_matrices, axis = 0)\n",
    "    P = I - get_rowspace_projection_torch(Q)\n",
    "\n",
    "    return P\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c85a47ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8603888888888889\n",
      "0.8057\n"
     ]
    }
   ],
   "source": [
    "# Baseline for background (all features)\n",
    "clf = LogisticRegression(random_state=0, multi_class='multinomial', max_iter=400, C = 0.1).fit(train_activations, train_backgrounds)\n",
    "print(clf.score(train_activations, train_backgrounds))\n",
    "print(clf.score(val_activations, val_backgrounds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f43ae447",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  7.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9842333333333333\n",
      "0.8144\n"
     ]
    }
   ],
   "source": [
    "#baseline for foreground (all features)\n",
    "clf = LogisticRegression(random_state=0, multi_class='multinomial', max_iter=400, C = 0.1, verbose=1).fit(train_activations, train_classes)\n",
    "print(clf.score(train_activations, train_classes))\n",
    "print(clf.score(val_activations, val_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4d83221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8603888888888889\n",
      "0.8057\n",
      "0.7753666666666666\n",
      "0.7577\n",
      "0.7213222222222222\n",
      "0.7134\n",
      "0.6795666666666667\n",
      "0.6734\n",
      "0.6403666666666666\n",
      "0.6352\n",
      "0.6023888888888889\n",
      "0.6012\n",
      "0.5635111111111111\n",
      "0.5667\n",
      "0.5238222222222222\n",
      "0.5279\n",
      "0.4902111111111111\n",
      "0.4939\n",
      "0.45587777777777777\n",
      "0.4616\n",
      "0.42344444444444446\n",
      "0.4307\n",
      "0.39344444444444443\n",
      "0.399\n",
      "0.3653222222222222\n",
      "0.3695\n",
      "0.3380111111111111\n",
      "0.3391\n",
      "0.3123444444444444\n",
      "0.3207\n",
      "0.29102222222222224\n",
      "0.3015\n",
      "0.2732111111111111\n",
      "0.2808\n",
      "0.2579888888888889\n",
      "0.2686\n",
      "0.24657777777777778\n",
      "0.2547\n",
      "0.23303333333333334\n",
      "0.2398\n",
      "0.21876666666666666\n",
      "0.2267\n",
      "0.20578888888888888\n",
      "0.207\n",
      "0.1928111111111111\n",
      "0.1923\n"
     ]
    }
   ],
   "source": [
    "# Iteratively find subspaces with background info\n",
    "train_activations_proj = train_activations\n",
    "val_activations_proj = val_activations\n",
    "rowspace_projections = []\n",
    "\n",
    "# Let's go for < 20% val accuracy:\n",
    "val_acc = 1.\n",
    "while (True):\n",
    "    clf = LogisticRegression(random_state=0, multi_class='multinomial', max_iter=400, C = 0.1).fit(train_activations_proj, train_backgrounds)\n",
    "    print(clf.score(train_activations_proj, train_backgrounds))\n",
    "    val_acc = clf.score(val_activations_proj, val_backgrounds)\n",
    "    print(val_acc)\n",
    "    if (val_acc < .2):\n",
    "        break\n",
    "    W = clf.coef_\n",
    "    P_rowspace_wi = get_rowspace_projection_torch(W)\n",
    "    rowspace_projections.append(P_rowspace_wi)\n",
    "    P = get_projection_to_intersection_of_nullspaces_torch(rowspace_projections, 2048)\n",
    "    train_activations_proj = (P.dot(train_activations.T)).T\n",
    "    val_activations_proj = (P.dot(val_activations.T)).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d9320a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_proj_after_it(it):\n",
    "    # Get foreground projection matrix \n",
    "    rowspace_projections_temp = rowspace_projections[:it]\n",
    "    P = get_projection_to_intersection_of_nullspaces_torch(rowspace_projections_temp, 2048)\n",
    "    # Get background projection matrix\n",
    "    anti_P = get_projection_to_intersection_of_nullspaces_torch([P],2048)\n",
    "    # Truncate matrices to proper dimension (this should be done already, but matrices end up being slightly larger due to numerical instability)\n",
    "    P_trunc = (orth_torch(P)[:,:2048-10*it]).T\n",
    "    anti_P_trunc = (orth_torch(anti_P)[:,:10*it]).T\n",
    "    # Project data \n",
    "    train_activations_antiproj = (anti_P_trunc.dot(train_activations.T)).T\n",
    "    val_activations_antiproj = (anti_P_trunc.dot(val_activations.T)).T\n",
    "    train_activations_proj = (P_trunc.dot(train_activations.T)).T\n",
    "    val_activations_proj = (P_trunc.dot(val_activations.T)).T\n",
    "    # Train and evaluate classifiers using projected heads\n",
    "    print(\"Background features, backgound accs\")\n",
    "    clf = LogisticRegression(random_state=0, multi_class='multinomial', max_iter=400, C = 0.1, verbose=1).fit(train_activations_antiproj, train_backgrounds)\n",
    "    print(clf.score(train_activations_antiproj, train_backgrounds))\n",
    "    print(clf.score(val_activations_antiproj, val_backgrounds))\n",
    "    print(\"Background features, foreground accs\")\n",
    "    clf = LogisticRegression(random_state=0, multi_class='multinomial', max_iter=400, C = 0.1, verbose=1).fit(train_activations_antiproj, train_classes)\n",
    "    print(clf.score(train_activations_antiproj, train_classes))\n",
    "    print(clf.score(val_activations_antiproj, val_classes))\n",
    "    print(\"Foreground features, backgound accs\")\n",
    "    clf = LogisticRegression(random_state=0, multi_class='multinomial', max_iter=400, C = 0.1, verbose=1).fit(train_activations_proj, train_backgrounds)\n",
    "    print(clf.score(train_activations_proj, train_backgrounds))\n",
    "    print(clf.score(val_activations_proj, val_backgrounds))\n",
    "    print(\"Foreground features, foreground accs\")\n",
    "    clf = LogisticRegression(random_state=0, multi_class='multinomial', max_iter=400, C = 0.1, verbose=1).fit(train_activations_proj, train_classes)\n",
    "    print(clf.score(train_activations_proj, train_classes))\n",
    "    print(clf.score(val_activations_proj, val_classes))\n",
    "    # Confirm invertability; will except otherwise\n",
    "    np.linalg.inv(np.concatenate([P_trunc,anti_P_trunc]))\n",
    "    return P_trunc, anti_P_trunc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4171957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background features, backgound accs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8606\n",
      "0.8053\n",
      "Background features, foreground accs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   47.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5676555555555556\n",
      "0.5221\n",
      "Foreground features, backgound accs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39287777777777777\n",
      "0.399\n",
      "Foreground features, foreground accs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  5.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9814555555555555\n",
      "0.8134\n"
     ]
    }
   ],
   "source": [
    "P_11, anti_P_11 = test_proj_after_it(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a7fc5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background features, backgound accs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8605111111111111\n",
      "0.8059\n",
      "Background features, foreground accs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   58.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7582222222222222\n",
      "0.692\n",
      "Foreground features, backgound accs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1925888888888889\n",
      "0.1918\n",
      "Foreground features, foreground accs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  5.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9785666666666667\n",
      "0.8124\n"
     ]
    }
   ],
   "source": [
    "P_22, anti_P_22 = test_proj_after_it(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "007906c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background features, backgound accs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =         1110     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.07233D+05    |proj g|=  1.90914D+04\n",
      "\n",
      "At iterate   50    f=  4.44203D+04    |proj g|=  2.23931D+01\n",
      "\n",
      "At iterate  100    f=  4.44060D+04    |proj g|=  4.72462D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      " 1110    115    120      1     0     0   1.008D-01   4.441D+04\n",
      "  F =   44405.945657474040     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =       111000     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.21698D+05    |proj g|=  1.28563D+02\n",
      "\n",
      "At iterate   50    f=  4.31286D+05    |proj g|=  3.88700D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "*****     74     83      1     0     0   1.688D-01   4.313D+05\n",
      "  F =   431283.70824748516     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        19390     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.07233D+05    |proj g|=  1.34538D+03\n",
      "\n",
      "At iterate   50    f=  1.68243D+05    |proj g|=  7.41433D+01\n",
      "\n",
      "At iterate  100    f=  1.67941D+05    |proj g|=  3.06494D+01\n",
      "\n",
      "At iterate  150    f=  1.67926D+05    |proj g|=  3.94411D+00\n",
      "\n",
      "At iterate  200    f=  1.67926D+05    |proj g|=  1.35418D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "19390    231    242      1     0     0   5.899D-01   1.679D+05\n",
      "  F =   167925.50252829454     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =      1939000     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.21698D+05    |proj g|=  7.15683D+01\n",
      "\n",
      "At iterate   50    f=  5.25247D+04    |proj g|=  6.14217D+00\n",
      "\n",
      "At iterate  100    f=  5.24242D+04    |proj g|=  1.12859D+00\n",
      "\n",
      "At iterate  150    f=  5.24219D+04    |proj g|=  1.04473D-01\n",
      "\n",
      "At iterate  200    f=  5.24218D+04    |proj g|=  3.09647D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "*****    205    218      1     0     0   3.605D-02   5.242D+04\n",
      "  F =   52421.826239962531     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =         2210     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.07233D+05    |proj g|=  6.75663D+03\n",
      "\n",
      "At iterate   50    f=  4.44554D+04    |proj g|=  3.70424D+01\n",
      "\n",
      "At iterate  100    f=  4.44026D+04    |proj g|=  8.48777D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      " 2210    131    136      1     0     0   9.048D-01   4.440D+04\n",
      "  F =   44402.483765721481     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =       221000     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.21698D+05    |proj g|=  8.07571D+01\n",
      "\n",
      "At iterate   50    f=  2.60590D+05    |proj g|=  2.78158D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "*****     87     91      1     0     0   2.066D-01   2.606D+05\n",
      "  F =   260583.53634275150     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        18290     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.07233D+05    |proj g|=  3.37046D+02\n",
      "\n",
      "At iterate   50    f=  2.02337D+05    |proj g|=  1.79992D+01\n",
      "\n",
      "At iterate  100    f=  2.02314D+05    |proj g|=  3.11681D+00\n",
      "\n",
      "At iterate  150    f=  2.02313D+05    |proj g|=  6.27963D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "18290    162    174      1     0     0   4.532D-01   2.023D+05\n",
      "  F =   202313.48371767625     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =      1829000     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.21698D+05    |proj g|=  7.12649D+01\n",
      "\n",
      "At iterate   50    f=  5.50146D+04    |proj g|=  3.31504D+00\n",
      "\n",
      "At iterate  100    f=  5.49145D+04    |proj g|=  1.48495D+00\n",
      "\n",
      "At iterate  150    f=  5.49125D+04    |proj g|=  6.96347D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "*****    197    209      1     0     0   2.005D-02   5.491D+04\n",
      "  F =   54912.477150541163     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          810     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.07233D+05    |proj g|=  1.09038D+04\n",
      "\n",
      "At iterate   50    f=  4.44161D+04    |proj g|=  1.99528D+01\n",
      "\n",
      "At iterate  100    f=  4.44081D+04    |proj g|=  1.66068D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "0.8605888888888888\n",
      "0.806\n",
      "Background features, foreground accs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4306888888888889\n",
      "0.3874\n",
      "Foreground features, backgound accs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4904\n",
      "0.4947\n",
      "Foreground features, foreground accs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  6.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9820888888888889\n",
      "0.8134\n"
     ]
    }
   ],
   "source": [
    "P_8, anti_P_8 = test_proj_after_it(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f8b222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save projection heads\n",
    "\n",
    "torch.save({'foreground': torch.tensor(P_8.T),'background': torch.tensor(anti_P_8.T) }, \"disentangle_8.pth\")\n",
    "\n",
    "torch.save({'foreground': torch.tensor(P_11.T),'background': torch.tensor(anti_P_11.T) }, \"disentangle_11.pth\")\n",
    "\n",
    "torch.save({'foreground': torch.tensor(P_22.T),'background': torch.tensor(anti_P_22.T) }, \"disentangle_22.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0595a94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
